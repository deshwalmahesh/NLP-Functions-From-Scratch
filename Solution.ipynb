{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import math\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_reader(corpusfile, lexicon=None): \n",
    "    with open(corpusfile,'r') as corpus: \n",
    "        for line in corpus: \n",
    "            if line.strip():\n",
    "                sequence = line.lower().strip().split()\n",
    "                if lexicon: \n",
    "                    yield [word if word in lexicon else \"UNK\" for word in sequence]\n",
    "                else: \n",
    "                    yield sequence\n",
    "                    \n",
    "\n",
    "def get_lexicon(corpus):\n",
    "    word_counts = defaultdict(int)\n",
    "    for sentence in corpus:\n",
    "        for word in sentence: \n",
    "            word_counts[word] += 1\n",
    "    return set(word for word in word_counts if word_counts[word] > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(inp, n):\n",
    "    \"\"\"\n",
    "    Given a sequence, this function should return a list of n-grams, where each n-gram is a Python tuple.\n",
    "    This should work for arbitrary values of 1 <= n < len(sequence).\n",
    "    \"\"\"\n",
    "    if type(inp) == str:\n",
    "        sequence = inp.split()\n",
    "    else:\n",
    "        sequence = inp.copy()\n",
    "        \n",
    "    end = len(sequence)\n",
    "    error = 0\n",
    "    result = []\n",
    "    start = 0\n",
    "\n",
    "    \n",
    "    sequence.insert(0,'START')\n",
    "    sequence.append('STOP')\n",
    "    end+=2\n",
    "    \n",
    "    if n==1:\n",
    "        return sequence\n",
    "    \n",
    "    else:\n",
    "        while start+n<end+1:\n",
    "            result.append(tuple(sequence[start:start+n]))\n",
    "            start+=1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrigramModel(object):\n",
    "    \n",
    "    def __init__(self, corpusfile):\n",
    "        \n",
    "        self.total_words = 0\n",
    "        # Iterate through the corpus once to build a lexicon \n",
    "        generator = corpus_reader(corpusfile)\n",
    "        self.lexicon = get_lexicon(generator)\n",
    "        self.lexicon.add(\"UNK\")\n",
    "        self.lexicon.add(\"START\")\n",
    "        self.lexicon.add(\"STOP\")\n",
    "    \n",
    "        # Now iterate through the corpus again and count ngrams\n",
    "        generator = corpus_reader(corpusfile, self.lexicon)\n",
    "        self.count_ngrams(generator)\n",
    "\n",
    "\n",
    "    def count_ngrams(self, corpus):\n",
    "        \"\"\"\n",
    "        Given a corpus iterator, populate dictionaries of unigram, bigram,\n",
    "        and trigram counts. \n",
    "        \"\"\"\n",
    "        \n",
    "        one_g = []\n",
    "        two_g = []\n",
    "        three_g = []\n",
    "        for sequence in corpus:\n",
    "            self.total_words += len(sequence)\n",
    "            one_g.extend(get_ngrams(sequence,1))\n",
    "            two_g.extend(get_ngrams(sequence,2))\n",
    "            three_g.extend(get_ngrams(sequence,3))\n",
    "            \n",
    "        self.unigramcounts = Counter(one_g)\n",
    "        self.bigramcounts = Counter(two_g)\n",
    "        self.trigramcounts = Counter(three_g)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def raw_trigram_probability(self,trigram):\n",
    "        \"\"\"\n",
    "        Returns the raw (unsmoothed) trigram probability\n",
    "        \"\"\"\n",
    "        assert len(trigram)==3, \"Input should be 3 words\"\n",
    "        if self.bigramcounts[trigram[:2]] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.trigramcounts[trigram]/self.bigramcounts[trigram[:2]]\n",
    "\n",
    "    \n",
    "    def raw_bigram_probability(self, bigram):\n",
    "        \"\"\"\n",
    "        Returns the raw (unsmoothed) bigram probability\n",
    "        \"\"\"\n",
    "        assert len(bigram)==2, \"Input should be 2 words\"\n",
    "        if self.unigramcounts[bigram[0]] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.bigramcounts[bigram]/self.unigramcounts[bigram[0]]\n",
    "        \n",
    "    \n",
    "    def raw_unigram_probability(self, unigram):\n",
    "        \"\"\"\n",
    "        Returns the raw (unsmoothed) unigram probability.\n",
    "        \"\"\"\n",
    "        uni = []\n",
    "        uni.append(unigram)\n",
    "        assert len(uni)==1, \"Input should be only 1 word\"\n",
    "        return self.unigramcounts[unigram]/self.total_words\n",
    "\n",
    "\n",
    "    def smoothed_trigram_probability(self, trigram):\n",
    "        \"\"\"\n",
    "        Returns the smoothed trigram probability (using linear interpolation). \n",
    "        \"\"\"\n",
    "        assert len(trigram)==3, \"Input should be 3 words\"\n",
    "        lambda1 = 1/3.0\n",
    "        lambda2 = 1/3.0\n",
    "        lambda3 = 1/3.0\n",
    "        u,v,w = trigram[0],trigram[1],trigram[2]\n",
    "        prob =  (lambda1*self.raw_unigram_probability(w))+\\\n",
    "        (lambda2*self.raw_bigram_probability((v,w)))+\\\n",
    "        (lambda3*self.raw_trigram_probability((u,v,w)))\n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def sentence_logprob(self, sentence):\n",
    "        \"\"\"\n",
    "        Returns the log probability of an entire sequence.\n",
    "        \"\"\"\n",
    "        from math import log2\n",
    "        if type(sentence) == str:\n",
    "            sentence = sentence.split()\n",
    "        tri_g = get_ngrams(sentence,3)\n",
    "        sent_prob = 0.0\n",
    "        for tri_tuple in tri_g:\n",
    "            sent_prob += log2(self.smoothed_trigram_probability(tri_tuple))\n",
    "            \n",
    "        return sent_prob\n",
    "    \n",
    "    \n",
    "    def perplexity(self, corpus):\n",
    "        \"\"\" \n",
    "        Returns the log probability of an entire sequence.\n",
    "        \"\"\"\n",
    "        if type(corpus) == 'str':\n",
    "            corpus = corpus_reader(corpus, self.lexicon)\n",
    "        \n",
    "        total_log_prob = 0.0\n",
    "        for sentence in corpus:\n",
    "            total_log_prob += self.sentence_logprob(sentence)\n",
    "        \n",
    "        l = total_log_prob/self.total_words\n",
    "        \n",
    "        return float(2**(-l))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def essay_scoring_experiment(training_file1, training_file2, testdir1, testdir2):\n",
    "\n",
    "        model1 = TrigramModel(training_file1)\n",
    "        model2 = TrigramModel(training_file2)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0       \n",
    " \n",
    "        for f in os.listdir(testdir1):\n",
    "            pp = model1.perplexity(corpus_reader(os.path.join(testdir1, f), model1.lexicon))\n",
    "            pp_low = model2.perplexity(corpus_reader(os.path.join(testdir1, f), model2.lexicon))\n",
    "            \n",
    "            if pp < pp_low:\n",
    "                correct += 1\n",
    "            else:\n",
    "                correct -= 1\n",
    "            total += 1\n",
    "    \n",
    "        for f in os.listdir(testdir2):\n",
    "            pp = model2.perplexity(corpus_reader(os.path.join(testdir2, f), model2.lexicon))\n",
    "            pp_high = pp = model1.perplexity(corpus_reader(os.path.join(testdir2, f), model1.lexicon))\n",
    "        \n",
    "            if pp < pp_high:\n",
    "                correct += 1\n",
    "            else:\n",
    "                correct -= 1\n",
    "            \n",
    "            total += 1\n",
    "        \n",
    "        return float(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47410358565737054"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_file1 = 'data/ets_toefl_data/train_high.txt'\n",
    "training_file2 =  'data/ets_toefl_data/train_low.txt'\n",
    "testdir1 = 'data/ets_toefl_data/test_high/'\n",
    "testdir2 = 'data/ets_toefl_data/test_low/'\n",
    "essay_scoring_experiment(training_file1, training_file2, testdir1, testdir2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
